#!/usr/bin/env python

# This script lets us dynamically configure sbatch for a sweep without needing to
# manually write a new sbatch script for each sweep.

import argparse
import os
import subprocess
from pathlib import Path

EXPERIMENT_BASE_DIR = "/usr/xtmp/jcd97/proto-rset/wandb/"
CUB200_DIR = "/usr/xtmp/lam135/datasets/CUB_200_2011_2/"
DOGS_DIR = "/usr/xtmp/jcd97/datasets/stanford_dogs/"
CARS_DIR = "/usr/xtmp/jcd97/datasets/cars/"


def write_file(
    *,
    full_sweep_id,
    sweep_runtime_limit,
    mode,
    mem,
    gres,
    output_dir,
    job_log_base,
    backbone,
    dataset,
    class_specific,
    bias_rate,
):

    entity, project, sweep_id = full_sweep_id.split("/")

    parent_dir = Path(__file__).parent.resolve()
    log_dir = job_log_base / mode / "logs" / sweep_id
    log_dir.mkdir(parents=True, exist_ok=True)
    # Save the output
    output_dir.mkdir(parents=True, exist_ok=True)
    output_filename = (output_dir.resolve() / sweep_id).with_suffix(".sh")

    print("directing logs to", log_dir)

    print("writing notebook to", output_filename)
    with open(output_filename, "w", encoding="utf-8") as f:
        f.write("#!/bin/sh\n")
        f.write(f"#SBATCH --mem={mem}\n")
        if gres is not None:
            f.write(f"#SBATCH --gres={gres}\n")
        f.write(f"#SBATCH --job-name=sw-{sweep_id}\n")
        f.write(f"#SBATCH --output={log_dir}/%x-%j.out\n")
        f.write("\n\n")
        f.write(f'echo "initializing agent for sweep {sweep_id}"\n\n')

        f.write(f"export WANDB_DIR={EXPERIMENT_BASE_DIR}/{mode}\n")
        f.write(f"export WANDB_CACHE_DIR={EXPERIMENT_BASE_DIR}/.cache\n")

        # this is for sweep runtime capping
        f.write(f"export WANDB_SWEEP_ID={sweep_id}\n")
        f.write(f"export WANDB_ENTITY={entity}\n")
        f.write(f"export WANDB_PROJECT={project}\n")
        f.write(f"export WANDB_RUNTIME_LIMIT={sweep_runtime_limit}\n")
        f.write(f"export BIAS_RATE={bias_rate}\n")

        f.write(
            f"export PPNXT_ARTIFACT_DIR={EXPERIMENT_BASE_DIR}/{mode}/artifacts/{sweep_id}\n"
        )
        f.write(f"export PPNXT_BACKBONE={backbone}\n")
        f.write(f"export PPNXT_CLASS_SPECIFIC={class_specific}\n")
        f.write(f"export CUB200_DIR={CUB200_DIR}\n")
        f.write(f"export DOGS_DIR={DOGS_DIR}\n")
        f.write(f"export CARS_DIR={CARS_DIR}\n")
        f.write(f"export TARGET_DATASET={dataset}\n")
        f.write(f"PYTHONPATH={parent_dir.parent} wandb agent {full_sweep_id}\n")

    return output_filename


if __name__ == "__main__":
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument(
        "full_sweep_id",
        type=str,
        help="The full sweep id generated by weights and biases.",
    )
    arg_parser.add_argument(
        "--dispatch",
        type=str,
        default="sbatch",
        help="command to run the resulting job script.",
    )
    arg_parser.add_argument(
        "--mode",
        type=str,
        default="test",
        choices=["test", "live"],
        help="Test run or live run.",
    )
    arg_parser.add_argument(
        "--mem", type=str, default="8G", help="The memory to allocate for the job."
    )
    arg_parser.add_argument(
        "--gres", type=str, default=None, help="Slurm gres to request for the job."
    )
    arg_parser.add_argument(
        "--output-dir",
        type=Path,
        default=(Path(__file__).parent / "slurm").resolve(),
    )
    arg_parser.add_argument(
        "--job-log-base",
        type=Path,
        default=Path(EXPERIMENT_BASE_DIR).resolve(),
    )
    arg_parser.add_argument(
        "--n-jobs",
        "-n",
        type=int,
        default=1,
        help="The number of agent jobs to run in parallel",
    )
    arg_parser.add_argument(
        "--backbone",
        type=str,
        default="vgg16",
        choices=[
            "vgg16",
            "vgg19",
            "resnet34",
            "resnet50",
            "densenet121",
            "densenet161",
            "convnext_b_22k",
            "convnext_l_22k",
        ],
        help="The backbone to use for the model.",
    )
    arg_parser.add_argument(
        "--dataset",
        type=str,
        default="CUB200",
        choices=["CUB200", "DOGS", "CARS", "CUB200_CROPPED", "HAM10000", "HAM10000_7CLASS_UPSAMPLE", "CUB200_10CLASS"],
        help="The dataset to use.",
    )
    arg_parser.add_argument(
        "--not-class-specific",
        default=False,
        action="store_true",
        help="Whether prototypes are restricted to a single class.",
    )
    arg_parser.add_argument(
        "--bias-rate",
        type=float,
        default=0.0,
        help="The rate at which to add bias patches to samples.",
    )
    arg_parser.add_argument(
        "--sweep-runtime-limit",
        type=float,
        default=259200.0,
        help="The run time limit for the whoel sweep in seconds",
    )
    args = arg_parser.parse_args()

    args_dict = vars(args)
    n_jobs = args_dict.pop("n_jobs")
    dispatch = args_dict.pop("dispatch")

    print("Not Class Specific", args_dict["not_class_specific"])

    args_dict["class_specific"] = not args_dict.pop("not_class_specific")

    print("Class Specific", args_dict["class_specific"])

    print("Creating sbatch script.")
    output_notebook = write_file(**args_dict)
    print("sweep script created at", output_notebook)

    subprocess.run(["chmod", "+x", str(output_notebook)])
    print("sweep script made executable")

    environment = os.environ.copy()
    environment["PYTHONPATH"] = f"{environment.get('PYTHONPATH', '')}:."

    for i in range(n_jobs):
        print("submitting job", i + 1, "of", n_jobs)
        subprocess.run([dispatch, str(output_notebook)], env=environment)

    print(
        f"Agents started on sbatch jobs. Add more agents by running\n> sbatch {str(output_notebook)}"
    )

    entity, project, sweep_id = args.full_sweep_id.split("/")
    print(f"Monitor Sweep at https://wandb.ai/{entity}/{project}/sweeps/{sweep_id}/")

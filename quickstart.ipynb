{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Before interacting with ProtoRSet, we run through a few setup steps:\n",
    "\n",
    "\n",
    "#### 1: If you are running in Google Collab, run the following cell to mount and point this notebook to the correct directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path_to_repo = \"/content/drive/path/to/code\"\n",
    "# !cp -r \"$path_to_repo\"/* ./\n",
    "# !pip install -r ./env/requirements-collab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Prepare a dataset\n",
    "In this demo, we'll use the CUB-200 image classification dataset. The following cell downloads, unzips, and splits the dataset. Note that this step may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "!wget https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz\n",
    "!tar -xvzf ./CUB_200_2011.tgz\n",
    "!python -m protopnet create-splits ./CUB_200_2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Prepare a reference ProtoPNet\n",
    "The following cell contains the code necessary to train your own reference ProtoPNet from scratch. Because training a neural network typically takes several hours, uncommented code instead downloads a trained ProtoPNet that we have provided for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines download a trained reference ProtoPNet\n",
    "!pip install gdown\n",
    "!gdown https://drive.google.com/uc?id=1c79gyWC4I3J1FxCPKV6wpY-Uqdr16ocU\n",
    "\n",
    "# # Uncomment and run the following lines to train a reference ProtoPNet\n",
    "# from protopnet.train_vanilla_cosine import run\n",
    "# import torch\n",
    "\n",
    "# ppn = run(\n",
    "#     dataset=\"CUB200\"\n",
    "# )\n",
    "\n",
    "# torch.save(ppn, \"./resnet50_cub200_ref_protopnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Prepare your ProtoRSet\n",
    "\n",
    "First we prepare dataloaders for the CUB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "os.environ[\"CUB200_DIR\"] = \"./CUB_200_2011/\"\n",
    "from protopnet.datasets import *\n",
    "\n",
    "batch_sizes = {\"train\": 20, \"project\": 20, \"val\": 20}\n",
    "split_dataloaders = training_dataloaders(\n",
    "    \"CUB200\",\n",
    "    data_path=os.environ[\"CUB200_DIR\"],\n",
    "    batch_sizes=batch_sizes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's finally time to fit our Proto-RSet! The following cell initializes and fits a Proto-RSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rashomon_sets.protorset_factory import ProtoRSetFactory\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "RSET_ARGS = {\n",
    "    \"rashomon_bound_multiplier\": 1.1, # The ratio of the maximum allowable loss to the minimum\n",
    "    \"lam\": 0.0001, # The weight to apply to our L2 regularization on the last layer\n",
    "    \"max_iter\": 5000,  # The max number of iterations allowed when fitting the optimal regression\n",
    "    \"device\": torch.device(\"cuda\"), # The device to use\n",
    "    \"lr_for_opt\": 1.0 # The learning rate to use when fitting the optimal regression\n",
    "}\n",
    "\n",
    "# The rset_factory object provides the main access point to interact with\n",
    "# a ProtoRSet, including the ability to produce a ProtoPNet object\n",
    "rset_factory = ProtoRSetFactory(\n",
    "    split_dataloaders=split_dataloaders,\n",
    "    initial_protopnet_path=Path(\"./resnet50_cub200_ref_protopnet.pth\"),\n",
    "    rashomon_set_args=RSET_ARGS,\n",
    "    device=\"cuda\",\n",
    "    reproject=False, # If true, perform a projection step after laoding in the reference ProtoPNet\n",
    "    verbose=False,\n",
    "    analysis_save_dir = Path(\n",
    "        \"./visualizations/\"  # This is where images used for visualization will be saved\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then precompute some self-activations for our prototypes to enable fast, repeated interactions and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = rset_factory.display_local_analysis(\n",
    "    49, # The image to visualize\n",
    "    run_proto_vis=True, # WARNING: Set this to False if running repeatedly. If true, this will save self-activations for every prototype.\n",
    "    include_coef=True, # Whether to include the last layer coefficient in the visualization\n",
    "    sort_using_logit=False # If True, show the 3 prototypes with the highest logit for any class; if False, instead sort by prototype activation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: Examine and interact with available ProtoPNets\n",
    "We're now ready to start playing with a ProtoRSet. The following cell runs a local analysis on the specified image index using the optimal ProtoPNet from the training set, meeting all current constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = rset_factory.display_local_analysis(\n",
    "    49, # The image to visualize\n",
    "    run_proto_vis=False, # WARNING: Set this to False if running repeatedly. If true, this will save self-activations for every prototype.\n",
    "    include_coef=True, # Whether to include the last layer coefficient in the visualization\n",
    "    sort_using_logit=False # If True, show the 3 prototypes with the highest logit for any class; if False, instead sort by prototype activation\n",
    ")\n",
    "img = Image.open(res_path[0])\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this visualization, we can identify prototypes we do/do not like. Say we think prototype 0 is confounded -- we can then remove this prototype as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_proto = 108\n",
    "# Check the accuracy of our best model before adding this constraint\n",
    "print(f\"Best validation accuracy before constraint: {rset_factory._best_val_acc().item()}\")\n",
    "# And check the coefficient on the target prototype in our optimal\n",
    "# model before adding the constraint\n",
    "pre_removal_coef = rset_factory.produce_protopnet_object().prototype_prediction_head.class_connection_layer.weight[:, target_proto].max()\n",
    "print(f\"Coefficient before constraint: {pre_removal_coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succesfully_removed = rset_factory.require_to_avoid_prototype(target_proto)\n",
    "print(\"Succesful removal!\" if succesfully_removed else \"Cannot remove this prototype.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of our best model after adding this constraint\n",
    "print(f\"Best validation accuracy after constraint: {rset_factory._best_val_acc().item()}\")\n",
    "# And check the coefficient on the target prototype in our optimal\n",
    "# model after adding the constraint\n",
    "post_removal_coef = rset_factory.produce_protopnet_object().prototype_prediction_head.class_connection_layer.weight[:, target_proto].max()\n",
    "print(f\"Coefficient after constraint: {post_removal_coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see a prototype that we would like more weight placed on, for now we should just keep track of it. The following cell notes that, down the line, we will want to produce a ProtoPNet with coefficient at least 10 on prototype 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_protos = [(3, 10), (17, 5), (100, 15)]\n",
    "# To track additional requirements of this kind, add more (protoype, coeff) tuples to this list, ie:\n",
    "# required_protos.append((prototype_index, coefficient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're done interacting with our ProtoRSet and think we've reached a satisfactory model, we can grab the optimal model that meets the given constraints using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = rset_factory.produce_protopnet_object_with_requirements(required_protos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in required_protos:\n",
    "  print(f\"Prototype {r[0]} cofficient:\\t {final_model.prototype_prediction_head.class_connection_layer.weight[:, r[0]].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
